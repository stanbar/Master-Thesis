\documentclass[nostrict]{szablonPG}
\usepackage[unicode=true]{hyperref}
\newcommand\PDFtitle{Application of blockchain and infection processes in graphs}
\newcommand\PDFauthors{Stanisław Barański}
\hypersetup{
  pdftitle={\PDFtitle},
  pdfauthor={\PDFauthors},
   pdfsubject={Mitigation Content Posioning},
   pdfkeywords={Content Poisoning, Blockchain, ICN, Graph infection}
 }
 
\usepackage{multicol} 
\makeatletter
\renewcommand{\verbatim@font}{\ttfamily\small}
\makeatother
 
\begin{document}

\tableofcontents
\listoffigures


\begin{abstract}
Information-centric networks introduce new vector of attacks, one of them is content poisoning, which when performed successfully, can create destructive damages. Currently known authentication methods like login/password, private key, biometry, SMS/email confirmation operate on the same dimension of authentication. We propose another dimension of authentication which is time availability. When intruder publisher is operating in time-constrained environment, his access to target identity is limited, whereas honest publisher is not constrained in any way. We leverage such distingshion to propose new authentication mechanism. Two implementations are proposed, first one is based on infection processes in graphs and second one is backed by blockchain technology. 


\end{abstract}



\section{Introduction - State of the art}
Current internet architecture is mostly based on TCP/IP stack, which allow  establish communication channels between two IP addresses. While it worked great for past years,  it struggle to fit current demands. Today internet is dominated by transporting content such as audio, video, images and text[source] from content creators to content consumers.
% Write more about how the internet is used today
% Write more about why current architecture doesn't fit 
% ICN - the solution !!!
The Information-centric networks like NDN\cite{zhang2014named}, DONA\cite{koponen2007data} or IPFS \cite{benet2014ipfs} introduce paradigm shift from host-centric to content-oriented paradigm. Placing content in the center of interest allow us to achieve number of benefits. All network participates become more aware of the transferring content. This kind of awareness allows to implement various improvements over host-based paradigm such as content caching, mobility, integrity and security assurance. All of those features are guaranteed naively by ICN transport layer in contrast to TCP/IP where we needed to build them on top of it.
% continue with Content protection in NDN

\section{Content Poisoning - Problem}
The most significant benefit of ICN networks is content caching. It turns out that this benefit becomes double-edged sword when we take into account security concerns. Attacker who successfully perform content-poisoning attack (CPA) on one content cache (CS), may achieve destructive success.
% can we say that?.
By attacker we understand malicious provider who gets access to a "signing machine" used by legitimate provider. In consequences it's impossible just by verifying packet signature to determine if the content is poisoned or not. Information-centric networks are designed to ease content diffusion, not matter if genuine or not. 

\section{Content Propagation Models}

\section{Fake News}
Fake News is an deliberate disinformative news that is hard to identify, and can lead to descructive consequences if not mitigated on time. Social media are perfect ecosystem for disseminating such kind of content, where the algorithms are designed to serve us the content we are likely to agree. In \cite{zhou2018fake} authors point out, why social media algorithms are very effective in fake news dissemination. Social media allow to form a similar minded people into groups, easier than ever before. Such groups facilitate Echo Chamber effect, where each individual is surrounded by people who share and produce content that fits our current world view. This leads to segmented and polarized society, which is very prone to believe in fake news that confirm current opinions, even if there is limited or no reason to believe in such. 


Fake News are written in very provocative fashion, making the content more attractive to interaction, more interaction lead to higher dissemination, which make even more interaction, and so on. While for honest publisher and valuable content this feature is helpful, it becomes very dangerous tool in hands of malicious publishers. Additionally the low cost of creating new accounts makes it even easier for attacker to initiate the snow-ball effect, using fake accounts. Bots can interact with people or even with other bots, creating fake social opinion.  

We notice that this concept fits perfectly into our Content Posioning Attack model. Thus it might be worth to reach some solutions used in that matter. 
In some sense, we are facing similar problem Fake News in social media does. We want to allow valuable content to spread really fast, and to reach as much people as possible, without any censorship. But the problem arises when we 
Fake News 
We notice that CPA is similar to Fake News. 

\subsection{How to mitigate fake news}
One idea is to create centralized services, that reveal known fake news. So each time someone is susceptible to some news, he can check if the news in not present in blacklisted news. Although this might seem great solution, it struggle with one significant flaw. Attacker can publish honest news in such "oracle" service, leading to revoking genuine news, which can he as harmful as fake news. Better way would be to check many services, and decide if they are convincing you, would be to  . 
Yet, the problem still persist during the first time such fake news is blacklisted in one of such services. 

\section{Wikipedia}
Wikipedia is great example of system that face with content poisoning problem. Let's investigate how do they solve the problem. 
Everyone can become Wikipedia editor just by creating free account. Account reqistration doesn't even require email address. Editor can create new article or modify existing one. But before the change is publicly available, other editors read the proposition, and have a chance to reject it or propose further edit. If they can not achieve consensus, they start a discussion where they exchange their arguments, finally if they agree on one version, consensus is achieved and new version of article is published (keeping the whole history of changes).
% What are the kinds of sockpuppeting 
% How to fight with sockpuppeting
% https://en.wikipedia.org/wiki/Wikipedia:Sock_puppetry
% they take into account the 5 phillars  etc. etc.
Such ease of account creation makes Wikipedia vulnerable to Sockpuppeting (also known as Sybil attack). This breach allows one user to create multiple accounts with different identity. In consequence, one person control fake "public opinion", which can support his position in edits discussions. That's why raw voting system is non-prefered method in conflict resolutions. Wikipedia consensus is rather collaborative, in contrast to competition consensus (e.g. used in Bitcoin where only one account who first find the proof-of-work wins all bitcoin reward). 
Wikipedia fight with content poisoning attacks, by using human to detect bogus changes. This mechanism seems to work well in such service, but it doesn't scale to public internet protocol.

\section{LOCKSS}
LOCKSS is decentralized p2p digital preservation system. It was build by Standford University for libraries \cite{maniatis2003preserving}. Currently it's open source, decentralized system used by many institutions. Helping them to maintain digital collection of journals, articles, books etc. If we abstract from the specific type of data the system is operating on. We notice that it has some similarities with ICN networks, that we believe are worth investigation. Main difference between LOCKSS and ICN is the fact that the former is very conservative, that mean it rather prevent, than expedite change of data. But this property may be useful in context of preventing bogus data diffusion. 
In LOCKSS, each participating library becomes a node in p2p network. Node run software that is responsible for collecting new content from e-journal websites by crawler, serving already stored materials to local readers, and cooperating with other nodes in preserving materials when they gets damaged. 
Due to copyrights of publishers, it's important that no node redistribute its content blindly to other peers. Other nodes can help to repair damaged or completely missed materials only to nodes that previously proved the ownership of such content. New materials can only be acquired directly from publisher website to libraries which paid for subscription. 
Damage detection is solved in cyclic polls, where each interested peer, vote on the hash of the storing Archive Unit (smallest unit in which nodes identify each content). Since each node consist of different set of Archive Units (AU), the protocol treat each AU independently. If it turns out that some node contains AU with different hash than majority of the poll, it start sequence of repairs. In result LOCKSS become self-healing store of data, and does not increase risk of free-loading non-purchased content.
LOCKSS is designed in a way that doesn't rely on long-time public-key cryptography. System that must operate for decades, is highly susceptible to eventually private-key leakage. Since it doesn't rely on public-key cryptography, the peer identity is very limited, therefore such system can not rely on peer reputations.


%\section{Bitcoin}
%Bitcoin is one of the most successfully maintained decentralized peer-to-peer system nowadays. Thus it's worth investigation on how they fight with CPA problem. We will look at two aspects of Bitcoin, first is project development, and second is Blockchain consensus.

%\subsection{Project Development}
%Although Bitcoin protocol is fully decentralized, its project development is maintained similar way Wikipedia does. Each change needs to be discussed by developers, everyone can join the discussion and express his opinion. Something that distinguishes Bitcoin from Wikipedia is the fact that two different versions of procol can coexists. If a proposed change doesn't 

\section{Consensus protocols}
Distributed systems require some kind of mechanism that let them achieve common state. We deep dive into different kind of consensus mechanisms that might be useful for our CPA problem.

%\section{DNS - Domain Name Server}

%\section{Satoshi consensus}
%Satoshi consensus based on proof-of-work was firstly introduced by Satoshi Nakamoto in Bitcoin Whitepaper.
%Bitcoin nodes uses consensus to acquire one common state on global ledger, called Blockchain. Bitcoin nodes achieve consensus by following common rules. The most significant rule require each block in blockchain \ref{blockchain}, must satisfy NP-hard puzzle in order to be validated and accepted. 

%\section{Proof-of-Stake}


%\section{Byzantine Agreement}


%\section{Federated Byzantine Agreement}
%Federated Byzatine Agreement (FBA) introduced in Stellar network is modification of Byzantine Agreement consensus protocol \cite{mazieres2015stellar}. Stellar is another blockchain network created for fast and cheap transfer of value. In contrast to Bitcoin's Satoshi Consensus, Stellar Consensus Protocol (SCP), doesn't use proof-of-work, instead construct called quorum slices is used to achieve consensus over global ledger. What makes SCP interesting for us, is the fact that it is model designed for internet level consensus. Additionally each node can freely chose the set of trusted nodes, to build so called quorum slice.


%\section{Blockchain}
%When we speak about trust, openness and decentralization it's always worth to consider Blockchain technology. Here we will try to use Blockchain to achieve previously stated requirements. Some of the properties Blockchain technology gives us are: immutability - once written, data can not be modified. Time assurance - each block is published in apprx. 10min. This feature gives us a clock that will provide us signed timestamps. Sign ensure trust based on consensus settled by proof-of-work algorithm.

\section{Proof of Time - Abstract solution}
We propose system where authentication is based on \textit{proof of time} access to private keys. 
We noticed that the proof-of-time must be published in either neutral place or in verifier place. So the publisher can not use it's influence to modify the data. 

\section{Trust graph}
How are they created ? In life, in networks ? What does it mean to create trust relationship. What do we understand by trust relationship. In environments that or another. 

Then we assume that such relation is already achieved. 
LOCKSS - solve the problem in one way, Wikipedia in another (experts consensus), but they doesn't fit to us, why ?. 

Why do we even look for solution for our problem in the context of human trust ? It turns out that people are still one of the most advanced technology, thus we can get inspired by some of the solutions that worked in human societies for centuries. Let's dive into it.
Yuval Noah Harari in his book "Sapiens: A Brief History of Humankind" states that the most important feature of human language is rumor. Rumor let us know which person is not trustworthy without having to interact with him directly. If our best friend Bob, tells us, that Carlie is theft, we don't need to get stolen to be convinced about it. Same applies in inverse scenario, if Bob tells us, that Carlie sells great quality products, we are now more likely to buy products from him. We notice that each person we know directly or indirectly, gets labeled by some tags. One can be labeled as Helpful, Conscientiousness and also Not-Trustworthy, while other can be labeled as Unhelpful, Lazy but Trustworthy. Here is this paper we are limiting our range of study just to dimension of trust.
What if we have three friends Alice, Bob, Charlie. Alice and  Bob tells us that David is Trustworthy, while Charlie claims that he's not. Decision of labeling David as Trustworthy or not, requires some kind of decision evaluation algorithm.
One might assume that if there is at least one person who doesn't trust him, there must be something wrong with him, and will label him as Not-Trustworthy. One can use the most natural to human beings evaluator which says, do want majority of people do, thus if Charlie is trusted by majority, I will trust her too. Another one can slightly generalise this evaluator and say that person is trustworthy, only if $\xi$ percentage of my friends trust him. 

At this point it's worth introducing some convention. When we say friend we mean a trustworthy person, in other words, person to who we have trust relation to. Let $N$ to be a set of all considered person group, friends and non-friends. Let $F$ be a set of all our friends $f \in F$. Let $F_n$ be a subset of $F$ where all $f$ trust person $n$. Then we will call $\%_n = |F_n|/|F|$ the proportion of our fiends who trust particular person $n$. Let's call $\xi$ (where $0 \le \xi \leq 1$) the minimum proportion of our friends $\%_n$ who needs to trust person $n$ in order to make me trust him. 

So as we said previously that we will trust David only if majority of our friends trust him. We denote trust function as $T(n) = \%_n > \xi : (N) \rightarrow \{0,1\}$. 
Let's use this formula to evaluate if $David$ is trustworthy person. Let $\xi = 0.5$. We know that Alice and Bob do trust David, while Charlie don't.
\[T(David) = \%_{David} > \xi\]
\[= |F_n|/|F| > \xi\]
\[= \frac{2}{3} > \frac{1}{2}\]
\[= 1\]
Then it turns out that $David$ is \textbf{Trustworthy}


People with low $\xi$ easly gets manipulated, we call them naive.
People with high $\xi$ hardly gets convinced, we call them stubborn. 

Another generalisation might be adding weights to this evaluator, let's say that Charlie is our brother, while Alice and Bob are our cousins, and we trust 3 times stronger to our brother than cousin. Let's call $W(f): (F) \rightarrow \Re$ the function that maps our friend to the weight of how strong we trust him. In this case weighted proportion of our friends \[\%_n = \frac{\sum\limits_f^{F_n} W(f)}{\sum\limits_f^{F} W(f)}\]

When we assume weights $W(Alice) = 1, W(Bob) = 1, W(Charlie) = 3$, and $\xi = 0.5$. We can calculate weighted proportion $T(David)$ as follows:
\[T(David) = \%_n > \xi\]
\[= \frac{\sum\limits_f^{F_n} W(f)}{\sum\limits_f^{F} W(f)} > \xi\]
\[= \frac{\sum \{1,1\}}{\sum\{1,1,3\}} > \frac{1}{2}\]
\[= \frac{2}{5} > \frac{1}{2}\]
\[= 0\]
Then it turns out that $David$ is \textbf{Not-Trustworthy}

But this view is based on static network of connections. We somehow meet Alice, Bob and Charlie, and we gets convinced about their trustworthness. Thus there must be a second way of gaining our trust. Let's modify our trust function by allowing External Trust Obtaining(ETO). $T(n) = \%_n > \xi \lor ETO(n) : (N) \rightarrow \{0,1\}$. 

Another think we can observe in the context of trust network is time. Should we still trust our friend from elementary school if we haven't seen him for decades ? We argue that trust is function of time.





\section{Stolen Credentials Problem}
How long on average does it take to detect stolen credentials on average.

\section{Graph Burning}
How does it differ from out solution ? Where to place fire so it burn as fast as possible ?


\section{Graph Infections - Concrete solution}
Proposition \cite{jekon2019content}
Simulator \url{https://github.com/stasbar/MASTI}

The graph we are considering is limited only to one content at a time. So we can assume that all nodes in the graph are interested in such content trust.

\section{Bitcoin - naive solution}
In previous section we discussed solution based on graph infections. Here we will propose naive solution based on one of the core features of Bitcoin Blockchain, precisely on probabilistic fixed interval between blocks creation. In bitcoin protocol, transactions are stored in data structure called Blockchain. Each node in p2p Bitcoin network can participate in block creation process called mining, this becoming miner. Each node becomes validator of new transactions that gets to Bitcoin network. follows strict rules that 

\section{Blockchain - Concrete solution}
We could use Bitcoin blockchain, or any other blockchain with constant time block creation, to persist proof-of-time claims. In Bitcoin each block is created in appx. 10min. We could take advantage of it, as a global, secure signing clock. Each new block has it's own unique hash, which can be used as a signing key. For our proof-of-time claims, or better we could persist our claims inside blockchain itself. Naive approach would be to send a empty (just fee) transaction from publisher account to hash of the content address. This way everyone can check, the history of hash of the content. Ensuring that it was proven by publisher for long enough. Of course this approach is conceptual. Bitcoin network is not suitable to operate in for network devices. Therefore we will outline the properties especially interesting in blockchain, and try to find out another blockhain or propose our own design. We consider Blockchain in first place, mainly because it's secure. Secure in terms of Byzantine Fault Tolerant system, but also as immutable storage. Not one can change the previously written data, without recalculating the proof-of-work puzzle, and overtaking rest of the network in computational power competition. This mechanisms works great for blockchains that servers store of value purposes. Our needs are completely different, we need a system that is asymptotic secure, so no (more powerful) node can overtake the whole network. That way, we lose the property of ~10min period ticking clock. We also can not incentivese nodes to behave honest by staking electrical power. We also need to get rid of fees since the Internet protocol on this level must be free. Therefore we need to protect from DoS attack in different way. Another important properties are openness and scalability. We need to design system that allow joining new participants and is highly scalable, otherwise we are limiting the protocol to special use cases, rather than global Internet protocol. Such software needs to operate on network devices which are resources constrained. Thus it needs to be lightweight, both in computational power and memory consumption.

Our solution to this problem is modification of \cite{jekon2019content}, by adding Blockchain as a storage, and modifying consensus algorithm.

Each publisher who wants to publish the content to the network, must start with its home node. That node, create transaction in which he certifies the content proved by the publisher. Such certificate is then flooded to whole network, so they can update the current state of trust to the content. After some delay (clock tic), such node also create certificate in which he point to the one of neighbours node which can be infected next, where the publisher is also allowed to publish the content. The next node will accept the infection only if he is an home publisher, or if he is pointed as the next node by the previous node. Publisher show valid certificate (signed by previous node, and by himself - proving access to private key). Each node can create certification only once per content. 

That way, each node control the time of infection dissemination. If any node notice, that, the new certification was published earlier than previous certification + some fixed delay, it can assume that such node is cheating, and filter the certifications from such node.

Therefore we constructed new consensus algorithm where each node spread infection only if:
- didn't spread the infection for such content before
- previous time of infection was x time ago
- it is the home publisher or contains authorization token issued by some neighbour pointing to the node.

\section{Fusion - Graph infection blockchain based scheme}
We notice that, the chain of approval can be threat like a blockchain. Consensus mechanism here is based purely on each node. Each node control the time delay of the next block. If some node block the transaction, or sends it faster than designed (malicious actor), we can distrust that node. Each external publication create next block. Publisher is responsible for extending that chain to the length of acceptable trust to that content.

\section{Comparison}
\begin{table}[]
\begin{tabular}{lll}
                                   & Graph Infections & Blockchain \\
Byzantine tolerant system          & False            & True       \\
Determined                         & False            & True       \\
Memory expensive                   & True             & True       \\
Progressive trust                  & False            & True       \\
Transport layer dependent          & True             & Optional   \\
Require Network topology awareness & True             & False     
\end{tabular}
\end{table}


\section{Discussion}

\bibliographystyle{plain}
\bibliography{refs}

\end{document}

